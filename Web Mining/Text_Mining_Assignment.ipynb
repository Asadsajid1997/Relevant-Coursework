{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rLGLyATi_Wh",
        "outputId": "6e29b713-3409-43da-c1d5-63fb789cb1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import csv\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XwgkA66Ki_Wk"
      },
      "outputs": [],
      "source": [
        "#function that loads a lexicon of positive words to a set and returns the set\n",
        "def loadLexicon(fname):\n",
        "    newLex=set()\n",
        "    lex_conn=open(fname)\n",
        "\n",
        "    #add every word in the file to the set\n",
        "    for line in lex_conn:\n",
        "        newLex.add(line.strip())# remember to strip to remove the lin-change character\n",
        "    lex_conn.close()\n",
        "\n",
        "    return newLex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Parse(input_file, index1, index2):\n",
        "    # Load the positive and negative lexicons into sets\n",
        "    posLex = loadLexicon('positive-words.txt')\n",
        "    negLex = loadLexicon('negative-words.txt')\n",
        "\n",
        "    noun_sentiment_index1 = {}  # Maps each noun to a tuple (positive count, negative count)\n",
        "    noun_sentiment_index2 = {}\n",
        "\n",
        "    fin = open(input_file, encoding='utf8', newline='')\n",
        "    reader = csv.reader(fin)\n",
        "\n",
        "    for i, line in enumerate(reader):\n",
        "        if i not in [index1]:  # Skip rows except for row 23\n",
        "            continue\n",
        "\n",
        "        text, rating = line  # Get the text and rating\n",
        "        sentences = sent_tokenize(text)  # Split the review into sentences\n",
        "\n",
        "        for sentence in sentences:  # For each sentence\n",
        "            words = word_tokenize(sentence)  # Split the sentence into words\n",
        "            tagged_words = nltk.pos_tag(words)  # Perform POS tagging on the words in the sentence\n",
        "\n",
        "            nouns_in_sentence = set()  # Set of all the nouns in the sentence\n",
        "            positive_word_count = 0  # Number of positive words in the sentence\n",
        "            negative_word_count = 0  # Number of negative words in the sentence\n",
        "\n",
        "            # Iterate over the tagged words\n",
        "            for tagged_word in tagged_words:\n",
        "                if tagged_word[1].startswith('NN'):  # If the word is a noun\n",
        "                    noun = tagged_word[0].lower()  # Lowercase the noun\n",
        "\n",
        "                    if len(noun) < 3:  # Ignore nouns with less than 3 characters\n",
        "                        continue\n",
        "\n",
        "                    nouns_in_sentence.add(noun)  # Add the noun to the set\n",
        "\n",
        "                if tagged_word[1].startswith('JJ'):  # If the word is an adjective\n",
        "                    if tagged_word[0] in posLex:  # Check if it is a positive word\n",
        "                        positive_word_count += 1\n",
        "                    elif tagged_word[0] in negLex:  # Check if it is a negative word\n",
        "                        negative_word_count += 1\n",
        "\n",
        "            for noun in nouns_in_sentence:  # For each noun found in the sentence\n",
        "                noun_sentiment_index1[noun] = (\n",
        "                    noun_sentiment_index1.get(noun, (0, 0))[0] + positive_word_count,\n",
        "                    noun_sentiment_index1.get(noun, (0, 0))[1] + negative_word_count\n",
        "                )\n",
        "\n",
        "    sorted_nouns_index1 = sorted(noun_sentiment_index1.items(), key=lambda x: sum(x[1]), reverse=True)\n",
        "\n",
        "    filtered_result_1 = [(noun, sentiment) for noun, sentiment in sorted_nouns_index1 if sentiment != (0, 0)]\n",
        "\n",
        "    filtered_result_1 = [(noun, 'Positive' if sentiment[0] > sentiment[1] else 'Negative' if sentiment[0] < sentiment[1] else 'Neutral') for noun, sentiment in filtered_result_1]\n",
        "\n",
        "\n",
        "\n",
        "    fin.seek(0)  # Reset the file position to the beginning\n",
        "\n",
        "    for i, line in enumerate(reader):\n",
        "        if i not in [index2]:  # Skip rows except for row 23\n",
        "            continue\n",
        "\n",
        "        text, rating = line  # Get the text and rating\n",
        "        sentences = sent_tokenize(text)  # Split the review into sentences\n",
        "\n",
        "        for sentence in sentences:  # For each sentence\n",
        "            words = word_tokenize(sentence)  # Split the sentence into words\n",
        "            tagged_words = nltk.pos_tag(words)  # Perform POS tagging on the words in the sentence\n",
        "\n",
        "            nouns_in_sentence = set()  # Set of all the nouns in the sentence\n",
        "            positive_word_count = 0  # Number of positive words in the sentence\n",
        "            negative_word_count = 0  # Number of negative words in the sentence\n",
        "\n",
        "            # Iterate over the tagged words\n",
        "            for tagged_word in tagged_words:\n",
        "                if tagged_word[1].startswith('NN'):  # If the word is a noun\n",
        "                    noun = tagged_word[0].lower()  # Lowercase the noun\n",
        "\n",
        "                    if len(noun) < 3:  # Ignore nouns with less than 3 characters\n",
        "                        continue\n",
        "\n",
        "                    nouns_in_sentence.add(noun)  # Add the noun to the set\n",
        "\n",
        "                if tagged_word[1].startswith('JJ'):  # If the word is an adjective\n",
        "                    if tagged_word[0] in posLex:  # Check if it is a positive word\n",
        "                        positive_word_count += 1\n",
        "                    elif tagged_word[0] in negLex:  # Check if it is a negative word\n",
        "                        negative_word_count += 1\n",
        "\n",
        "            for noun in nouns_in_sentence:  # For each noun found in the sentence\n",
        "                noun_sentiment_index2[noun] = (\n",
        "                    noun_sentiment_index2.get(noun, (0, 0))[0] + positive_word_count,\n",
        "                    noun_sentiment_index2.get(noun, (0, 0))[1] + negative_word_count\n",
        "                )\n",
        "\n",
        "    sorted_nouns_index2 = sorted(noun_sentiment_index2.items(), key=lambda x: sum(x[1]), reverse=True)\n",
        "\n",
        "    filtered_result_2 = [(noun, sentiment) for noun, sentiment in sorted_nouns_index2 if sentiment != (0, 0)]\n",
        "\n",
        "    filtered_result_2 = [(noun, 'Positive' if sentiment[0] > sentiment[1] else 'Negative' if sentiment[0] < sentiment[1] else 'Neutral') for noun, sentiment in filtered_result_2]\n",
        "\n",
        "    list_opposite_nouns = []\n",
        "    for noun1, sentiment1 in filtered_result_1:\n",
        "      for noun2, sentiment2 in filtered_result_2:\n",
        "        if noun1 == noun2 and sentiment1 != sentiment2:\n",
        "          print('Index1:', noun1, sentiment1)\n",
        "          print('Index2:', noun2, sentiment2)\n",
        "          list_opposite_nouns.append(noun1)\n",
        "\n",
        "    print(list_opposite_nouns)\n",
        "    print(filtered_result_1)\n",
        "    print(filtered_result_2)\n",
        "\n",
        "\n",
        "    fin.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HEl2o0iczkTU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_JlL-hyi_Wo",
        "outputId": "ef6745be-719a-43a4-8549-89bf8c469718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index1: sennheiser Positive\n",
            "Index2: sennheiser Negative\n",
            "['sennheiser']\n",
            "[('sennheiser', 'Positive'), ('hd650', 'Positive'), ('headphones', 'Positive'), ('lot', 'Positive'), ('noise', 'Positive'), ('cancelation', 'Positive'), ('app', 'Negative'), ('tile', 'Negative')]\n",
            "[('pair', 'Negative'), ('today', 'Neutral'), ('months', 'Neutral'), ('bluetooth', 'Neutral'), ('issues', 'Neutral'), ('side', 'Neutral'), ('disconnections', 'Neutral'), ('sennheiser', 'Negative')]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "result=Parse('amazonreviews.csv',36,50)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}